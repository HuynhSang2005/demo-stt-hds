# AI Agent Task Prompts â€“ Offline-First Speech-to-Text + Toxic Detection (Vietnamese)

> **Má»¥c tiÃªu**: XÃ¢y dá»±ng webapp local, **offline**, **real-time**, dÃ¹ng **2 mÃ´ hÃ¬nh Ä‘Ã£ clone sáºµn**:
> - `./models/wav2vec2-base-vietnamese-250h/`
> - `./models/phobert-vi-comment-4class/`
> 
> **YÃªu cáº§u chung**:
> - KhÃ´ng gá»i Hugging Face Hub (offline-only)
> - 
> - Real-time qua WebSocket (chunk ~2s)
> - Chá»‰ cáº£nh bÃ¡o khi label = `"toxic"` hoáº·c `"negative"`

---

## ğŸ”¹ GIAI ÄOáº N 1: XÃC MINH MODEL LOCAL

### âœ… Prompt 1.1 â€“ Kiá»ƒm tra tÃ­nh toÃ n váº¹n model
> "Kiá»ƒm tra folder `./models/wav2vec2-base-vietnamese-250h/` cÃ³ Ä‘á»§ cÃ¡c file sau:
> - `config.json`
> - `pytorch_model.bin`
> - `processor_config.json`
> - `vocab.json`
> - `tokenizer_config.json`
> 
> TÆ°Æ¡ng tá»±, kiá»ƒm tra `./models/phobert-vi-comment-4class/` cÃ³:
> - `config.json`
> - `pytorch_model.bin`
> - `tokenizer_config.json`
> - `special_tokens_map.json`
> 
> Náº¿u thiáº¿u file nÃ o â†’ bÃ¡o lá»—i rÃµ rÃ ng."

### âœ… Prompt 1.2 â€“ XÃ¡c minh load model offline
> "Viáº¿t script Python `verify_models.py`:
> - DÃ¹ng `Wav2Vec2Processor.from_pretrained(local_path, local_files_only=True)`
> - DÃ¹ng `Wav2Vec2ForCTC.from_pretrained(...)` tÆ°Æ¡ng tá»±
> - DÃ¹ng `pipeline('text-classification', model=..., local_files_only=True)`
> - In ra: `'âœ… ASR loaded'`, `'âœ… Classifier loaded'`
> - Náº¿u lá»—i â†’ in traceback vÃ  dá»«ng"

---

## ğŸ”¹ GIAI ÄOáº N 2: BACKEND â€“ OFFLINE INFERENCE & FASTAPI SETUP

### âœ… Prompt 2.1 â€“ Cáº¥u hÃ¬nh dá»± Ã¡n FastAPI
> "Táº¡o thÆ° má»¥c `backend/` vá»›i cáº¥u trÃºc:
> ```
> backend/
> â”œâ”€â”€ app/
> â”‚   â”œâ”€â”€ main.py
> â”‚   â”œâ”€â”€ core/
> â”‚   â”‚   â”œâ”€â”€ __init__.py
> â”‚   â”‚   â”œâ”€â”€ config.py        # PydanticSettings: model_paths
> â”‚   â”‚   â””â”€â”€ logger.py        # JSON structured logger
> â”‚   â”œâ”€â”€ models/
> â”‚   â”‚   â”œâ”€â”€ __init__.py
> â”‚   â”‚   â”œâ”€â”€ asr.py           # LocalWav2Vec2ASR
> â”‚   â”‚   â””â”€â”€ classifier.py    # LocalPhoBERTClassifier
> â”‚   â”œâ”€â”€ schemas/
> â”‚   â”‚   â””â”€â”€ audio.py         # Pydantic: TranscriptResult
> â”‚   â”œâ”€â”€ services/
> â”‚   â”‚   â””â”€â”€ audio_processor.py  # resample + pipeline
> â”‚   â””â”€â”€ api/
> â”‚       â””â”€â”€ v1/
> â”‚           â””â”€â”€ endpoints.py # WebSocket route
> â”œâ”€â”€ requirements.txt
> â””â”€â”€ README.md
> ```
> - `requirements.txt` pháº£i cÃ³: `fastapi`, `uvicorn`, `torch`, `transformers`, `torchaudio`, `onnxruntime` (tÃ¹y chá»n)
> - `config.py`: Ä‘á»‹nh nghÄ©a `ASR_MODEL_PATH = './models/wav2vec2-base-vietnamese-250h'`, `CLASSIFIER_MODEL_PATH = './models/phobert-vi-comment-4class'`"

### âœ… Prompt 2.2 â€“ Triá»ƒn khai ASR model tá»« local
> "Trong `backend/app/models/asr.py`, viáº¿t class `LocalWav2Vec2ASR`:
> - `__init__(self, model_path: str)`: load processor + model vá»›i `local_files_only=True`
> - `transcribe(self, audio_bytes: bytes) -> str`:
>   1. DÃ¹ng `io.BytesIO(audio_bytes)` â†’ `torchaudio.load()`
>   2. Náº¿u sample rate â‰  16000 â†’ resample báº±ng `torchaudio.functional.resample`
>   3. Äáº£m báº£o waveform shape = `(1, T)`
>   4. DÃ¹ng processor â†’ input_values â†’ model â†’ argmax â†’ decode
>   5. Tráº£ vá» text (str), khÃ´ng cÃ³ dáº¥u ngoáº·c, khÃ´ng log
> - Xá»­ lÃ½ exception â†’ tráº£ `'[ASR_ERROR]'`"

### âœ… Prompt 2.3 â€“ Triá»ƒn khai classifier tá»« local
> "Trong `backend/app/models/classifier.py`, viáº¿t class `LocalPhoBERTClassifier`:
> - `__init__(self, model_path: str)`: load pipeline vá»›i `local_files_only=True`
> - `predict(self, text: str) -> dict`:
>   - Náº¿u text rá»—ng â†’ tráº£ `{'label': 'neutral', 'score': 1.0}`
>   - Gá»i pipeline â†’ tráº£ `{'label': str, 'score': float}`
>   - Chá»‰ cháº¥p nháº­n 4 label: `positive|negative|neutral|toxic`"

### âœ… Prompt 2.4 â€“ WebSocket endpoint real-time
> "Trong `backend/app/api/v1/endpoints.py`:
> - Viáº¿t endpoint `websocket_endpoint(websocket: WebSocket)`:
>   1. `await websocket.accept()`
>   2. VÃ²ng láº·p `while True`:
>      - `data = await websocket.receive_bytes()`
>      - Gá»i `audio_processor.process(data)` â†’ tráº£ `TranscriptResult`
>      - `await websocket.send_json(result.dict())`
>   3. Báº¯t exception â†’ log lá»—i, khÃ´ng crash
> - ÄÄƒng kÃ½ route: `@app.websocket('/v1/ws')` trong `main.py`"

---

## ğŸ”¹ GIAI ÄOáº N 3: FRONTEND â€“ REAL-TIME UI & WEBSOCKET

### âœ… Prompt 3.1 â€“ Cáº¥u hÃ¬nh dá»± Ã¡n React + Vite
> "Táº¡o thÆ° má»¥c `frontend/` vá»›i:
> ```
> frontend/
> â”œâ”€â”€ src/
> â”‚   â”œâ”€â”€ app/page.tsx
> â”‚   â”œâ”€â”€ hooks/
> â”‚   â”‚   â”œâ”€â”€ useAudioRecorder.ts
> â”‚   â”‚   â””â”€â”€ useWebSocket.ts
> â”‚   â”œâ”€â”€ store/useStore.ts     # Zustand
> â”‚   â”œâ”€â”€ components/
> â”‚   â”‚   â”œâ”€â”€ TranscriptDisplay.tsx
> â”‚   â”‚   â””â”€â”€ RecordingButton.tsx
> â”‚   â””â”€â”€ types/index.ts        # TranscriptResult
> â”œâ”€â”€ tailwind.config.ts
> â””â”€â”€ package.json
> ```
> - CÃ i: `react`, `vite`, `zustand`, `wavesurfer.js`, `@radix-ui/react-*`, `shadcn-ui`
> - KhÃ´ng cÃ i `axios` (chá»‰ dÃ¹ng WebSocket)"

### âœ… Prompt 3.2 â€“ Hook ghi Ã¢m real-time
> "Viáº¿t `useAudioRecorder.ts`:
> - Tráº£ vá»: `{ isRecording: boolean, startRecording: () => void, stopRecording: () => void }`
> - BÃªn trong:
>   - `useRef<MediaRecorder | null>(null)`
>   - `navigator.mediaDevices.getUserMedia({ audio: true })`
>   - `new MediaRecorder(stream, { mimeType: 'audio/webm;codecs=opus' })`
>   - `ondataavailable`: gá»­i `e.data.arrayBuffer()` qua callback `onChunk`
>   - `onstop`: cleanup
> - Chunk interval: 2000ms"

### âœ… Prompt 3.3 â€“ Hook WebSocket client
> "Viáº¿t `useWebSocket.ts`:
> - Nháº­n `onMessage: (data: TranscriptResult) => void`
> - Tá»± Ä‘á»™ng connect Ä‘áº¿n `ws://localhost:8000/v1/ws`
> - PhÆ°Æ¡ng thá»©c `sendAudioChunk(chunk: ArrayBuffer)`
> - Xá»­ lÃ½ reconnect (3 láº§n, delay 1s)
> - DÃ¹ng `useRef<WebSocket>` Ä‘á»ƒ trÃ¡nh re-create"

### âœ… Prompt 3.4 â€“ UI hiá»ƒn thá»‹ real-time
> "Táº¡o component `TranscriptDisplay.tsx`:
> - DÃ¹ng Zustand store: `transcripts: { id: string; text: string; label: string; warning: boolean }[]`
> - Map qua máº£ng â†’ render tá»«ng dÃ²ng
> - Náº¿u `warning: true`:
>   - DÃ¹ng `<Badge variant='destructive'>{label}</Badge>`
>   - DÃ²ng text cÃ³ ná»n `bg-red-50/20`
> - Cuá»™n tá»± Ä‘á»™ng xuá»‘ng cuá»‘i khi cÃ³ dÃ²ng má»›i"

---

## ğŸ”¹ GIAI ÄOáº N 4: INTEGRATION & VALIDATION

### âœ… Prompt 4.1 â€“ Test end-to-end real-time
> "Viáº¿t hÆ°á»›ng dáº«n test:
> 1. Cháº¡y BE: `cd backend && uvicorn app.main:app --reload --port 8000`
> 2. Cháº¡y FE: `cd frontend && npm run dev`
> 3. Má»Ÿ `http://localhost:5173`
> 4. Nháº¥n 'Start Recording'
> 5. NÃ³i: 'Äá»“ ngá»‘c, mÃ y tháº­t lÃ  tá»‡!'
> 6. Kiá»ƒm tra:
>    - FE hiá»ƒn thá»‹ text gáº§n Ä‘Ãºng
>    - CÃ³ badge 'toxic' mÃ u Ä‘á»
>    - Latency < 2.5s
> 7. Log BE khÃ´ng cÃ³ lá»—i decode"

### âœ… Prompt 4.2 â€“ Viáº¿t README.md chuáº©n dev Viá»‡t
> "Táº¡o `README.md` á»Ÿ root:
> - TiÃªu Ä‘á»: 'Demo Local: Speech-to-Text + PhÃ¡t hiá»‡n ná»™i dung Ä‘á»™c háº¡i (Tiáº¿ng Viá»‡t)'
> - Má»¥c 'YÃªu cáº§u':
>   - Python 3.9+, Node 18+
>   - ÄÃ£ clone 2 model vÃ o `./models/`
> - Má»¥c 'CÃ¡ch cháº¡y':
>   ```bash
>   # Backend
>   cd backend
>   pip install -r requirements.txt
>   uvicorn app.main:app --port 8000
> 
>   # Frontend
>   cd frontend
>   npm install
>   npm run dev
>   ```
> - Má»¥c 'License':
>   - 'MÃ´ hÃ¬nh ASR: CC BY-NC 4.0 â€“ chá»‰ dÃ¹ng phi thÆ°Æ¡ng máº¡i'
>   - TrÃ­ch dáº«n Zenodo vÃ  email tÃ¡c giáº£ PhoBERT
> - Má»¥c 'Demo': áº£nh minh há»a (placeholder)"

---

## ğŸš« Cáº¤M
- Gá»i Hugging Face Hub
- DÃ¹ng librosa (pháº£i dÃ¹ng torchaudio)
- DÃ¹ng Axios hoáº·c REST API
- Deploy thÆ°Æ¡ng máº¡i

## âœ… HOÃ€N THÃ€NH KHI
- [ ] Cháº¡y local khÃ´ng cáº§n internet
- [ ] NÃ³i â†’ ra text â†’ phÃ¡t hiá»‡n 'toxic'
- [ ] CÃ³ test Ä‘Æ¡n vá»‹ (BE + FE)
- [ ] CÃ³ README rÃµ rÃ ng, trÃ­ch dáº«n Ä‘áº§y Ä‘á»§