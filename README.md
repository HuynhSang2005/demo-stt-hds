## üìã M·ª•c l·ª•c

> üöÄ **Mu·ªën setup nhanh?** Xem [QUICKSTART.md](QUICKSTART.md)

- [T√≠nh nƒÉng ch√≠nh](#-t√≠nh-nƒÉng-ch√≠nh)
- [Y√™u c·∫ßu h·ªá th·ªëng](#-y√™u-c·∫ßu-h·ªá-th·ªëng)
- [Ki·∫øn tr√∫c](#-ki·∫øn-tr√∫c)
- [H∆∞·ªõng d·∫´n c√†i ƒë·∫∑t](#-h∆∞·ªõng-d·∫´n-c√†i-ƒë·∫∑t)
- [H∆∞·ªõng d·∫´n ch·∫°y](#-h∆∞·ªõng-d·∫´n-ch·∫°y)
- [C·∫•u h√¨nh](#-c·∫•u-h√¨nh)
- [Troubleshooting](#-troubleshooting)
- [API Documentation](#-api-documentation)se Speech-to-Text + Toxic Detection System

H·ªá th·ªëng **Speech-to-Text (STT)** k·∫øt h·ª£p **ph√°t hi·ªán ng√¥n t·ª´ ti√™u c·ª±c** cho ti·∫øng Vi·ªát, ho·∫°t ƒë·ªông **offline-first** v·ªõi kh·∫£ nƒÉng real-time.

## üìã M·ª•c l·ª•c

- [T√≠nh nƒÉng ch√≠nh](#-t√≠nh-nƒÉng-ch√≠nh)
- [Y√™u c·∫ßu h·ªá th·ªëng](#-y√™u c·∫ßu-h·ªá-th·ªëng)
- [Ki·∫øn tr√∫c](#-ki·∫øn-tr√∫c)
- [H∆∞·ªõng d·∫´n c√†i ƒë·∫∑t](#-h∆∞·ªõng-d·∫´n-c√†i-ƒë·∫∑t)
- [H∆∞·ªõng d·∫´n ch·∫°y](#-h∆∞·ªõng-d·∫´n-ch·∫°y)
- [C·∫•u h√¨nh](#-c·∫•u-h√¨nh)
- [Troubleshooting](#-troubleshooting)
- [API Documentation](#-api-documentation)

## ‚ú® T√≠nh nƒÉng ch√≠nh

- üéØ **Speech-to-Text ti·∫øng Vi·ªát**: S·ª≠ d·ª•ng **PhoWhisper-small** (244M params) cho ƒë·ªô ch√≠nh x√°c cao
- üõ°Ô∏è **Ph√°t hi·ªán ng√¥n t·ª´ ti√™u c·ª±c**: PhoBERT classifier 4 classes (positive, neutral, negative, toxic)
- üîå **Offline-first**: Models ch·∫°y ho√†n to√†n local, kh√¥ng c·∫ßn internet sau khi setup
- ‚ö° **Real-time processing**: WebSocket connection v·ªõi latency th·∫•p
- üé® **Modern UI**: React + TypeScript + Tailwind CSS + Shadcn UI
- üìä **Audio visualization**: Waveform v·ªõi WaveSurfer.js
- üîÑ **Batch processing**: Micro-batching cho hi·ªáu su·∫•t t·ªët h∆°n

## üíª Y√™u c·∫ßu h·ªá th·ªëng

### Ph·∫ßn m·ªÅm b·∫Øt bu·ªôc

| Ph·∫ßn m·ªÅm | Phi√™n b·∫£n | M·ª•c ƒë√≠ch |
|----------|-----------|----------|
| **Python** | 3.9 - 3.13 | Backend runtime |
| **Node.js** | 18.x ho·∫∑c cao h∆°n | Frontend build tool |
| **FFmpeg** | 4.x ho·∫∑c cao h∆°n | X·ª≠ l√Ω audio WebM/Opus |
| **Git** | Latest | Clone repository |

### Ph·∫ßn c·ª©ng khuy·∫øn ngh·ªã

- **RAM**: 8GB+ (models load ~2GB)
- **Disk**: 5GB+ tr·ªëng (models + dependencies)
- **CPU**: 4 cores+ (ho·∫∑c GPU CUDA n·∫øu c√≥)

### H·ªá ƒëi·ªÅu h√†nh h·ªó tr·ª£

- ‚úÖ **Windows 10/11**
- ‚úÖ **macOS 11+** (Big Sur tr·ªü l√™n)
- ‚úÖ **Linux** (Ubuntu 20.04+, Debian 11+)

## üèóÔ∏è Ki·∫øn tr√∫c

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         WebSocket           ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                 ‚îÇ  ‚Üê‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí ‚îÇ                 ‚îÇ
‚îÇ  React Frontend ‚îÇ      (audio chunks)         ‚îÇ  FastAPI Backend‚îÇ
‚îÇ  (Port 5173)    ‚îÇ                             ‚îÇ  (Port 8000)    ‚îÇ
‚îÇ                 ‚îÇ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí  ‚îÇ                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      HTTP REST API          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                                         ‚îÇ
                                                         ‚Üì
                                         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                                         ‚îÇ   Local AI Models        ‚îÇ
                                         ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
                                         ‚îÇ ‚Ä¢ PhoWhisper-small       ‚îÇ
                                         ‚îÇ   (Speech-to-Text)       ‚îÇ
                                         ‚îÇ ‚Ä¢ PhoBERT Classifier     ‚îÇ
                                         ‚îÇ   (Toxic Detection)      ‚îÇ
                                         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Tech Stack

**Backend:**
- FastAPI 0.104.1 (Web framework)
- PyTorch 2.1.1 (ML framework)
- Transformers 4.35.2 (HuggingFace)
- torchaudio 2.1.1 (Audio processing)
- ONNX Runtime 1.16.3 (Inference optimization)

**Frontend:**
- React 19.1.1
- TypeScript 5.8.3
- Vite (Rolldown) 7.1.12
- Zustand 5.0.8 (State management)
- Zod 4.1.11 (Validation)
- Tailwind CSS 4.0 + Shadcn UI

## üì¶ H∆∞·ªõng d·∫´n c√†i ƒë·∫∑t

> üí° **Tip**: C√≥ th·ªÉ d√πng script t·ª± ƒë·ªông `setup.ps1` (Windows) ho·∫∑c `setup.sh` (Linux/Mac) ƒë·ªÉ skip c√°c b∆∞·ªõc manual!

### B∆∞·ªõc 0: Ki·ªÉm tra dependencies (Recommended)

```bash
# Clone repo tr∆∞·ªõc
git clone https://github.com/HuynhSang2005/demo-stt-hds.git
cd demo-stt-hds

# Ki·ªÉm tra dependencies
python check-dependencies.py
```

Script n√†y s·∫Ω ki·ªÉm tra:
- ‚úÖ Python version (3.9-3.13)
- ‚úÖ Node.js version (18+)
- ‚úÖ FFmpeg installation
- ‚úÖ pip v√† venv module
- ‚úÖ Disk space (5GB+)

N·∫øu pass t·∫•t c·∫£ checks, b·∫°n c√≥ th·ªÉ ch·∫°y:
- **Windows**: `.\setup.ps1`
- **Linux/Mac**: `bash setup.sh`

Ho·∫∑c ti·∫øp t·ª•c v·ªõi setup manual b√™n d∆∞·ªõi.

### B∆∞·ªõc 1: Clone repository (N·∫øu ch∆∞a clone)

```bash
git clone https://github.com/HuynhSang2005/demo-stt-hds.git
cd demo-stt-hds
```

### B∆∞·ªõc 2: C√†i ƒë·∫∑t FFmpeg

#### Windows:
```powershell
# D√πng Chocolatey (khuy·∫øn ngh·ªã)
choco install ffmpeg

# Ho·∫∑c download manual t·ª´: https://ffmpeg.org/download.html
# Sau ƒë√≥ th√™m v√†o PATH
```

#### macOS:
```bash
brew install ffmpeg
```

#### Linux (Ubuntu/Debian):
```bash
sudo apt-get update
sudo apt-get install ffmpeg
```

**Ki·ªÉm tra FFmpeg:**
```bash
ffmpeg -version
```

### B∆∞·ªõc 3: Setup Backend

```bash
cd backend

# T·∫°o virtual environment
python -m venv venv

# K√≠ch ho·∫°t virtual environment
# Windows PowerShell:
.\venv\Scripts\Activate.ps1
# Windows CMD:
.\venv\Scripts\activate.bat
# macOS/Linux:
source venv/bin/activate

# C√†i ƒë·∫∑t dependencies
pip install --upgrade pip
pip install -r requirements.txt
```

### B∆∞·ªõc 4: Download AI Models

Models s·∫Ω ƒë∆∞·ª£c download t·ª´ Hugging Face v·ªÅ local (~2.5GB):

```bash
# T·ª´ th∆∞ m·ª•c g·ªëc (demo-stt-hds/)
cd ..
python download_models.py
```

**Output mong ƒë·ª£i:**
```
üîÑ Checking PhoWhisper-small (Speech-to-Text)...
üì• Downloading PhoWhisper-small from HuggingFace...
‚úÖ PhoWhisper-small downloaded successfully!

üîÑ Checking phobert-vi-comment-4class (Sentiment Analysis)...
üì• Downloading phobert-vi-comment-4class from HuggingFace...
‚úÖ phobert-vi-comment-4class downloaded successfully!

üéâ Ho√†n th√†nh download models!
```

### B∆∞·ªõc 5: Setup Frontend

```bash
cd frontend

# C√†i ƒë·∫∑t dependencies v·ªõi npm
npm install

# Ho·∫∑c v·ªõi yarn
yarn install

# Ho·∫∑c v·ªõi pnpm (khuy·∫øn ngh·ªã, nhanh h∆°n)
pnpm install
```

### B∆∞·ªõc 6: T·∫°o file .env (Optional)

Backend s·∫Ω d√πng default config n·∫øu kh√¥ng c√≥ `.env`. N·∫øu mu·ªën customize:

```bash
cd backend
cp .env.example .env
# Sau ƒë√≥ ch·ªânh s·ª≠a .env theo nhu c·∫ßu
```

## üöÄ H∆∞·ªõng d·∫´n ch·∫°y

### Ch·∫°y Backend (Terminal 1)

```bash
cd backend

# K√≠ch ho·∫°t venv (n·∫øu ch∆∞a)
# Windows:
.\venv\Scripts\Activate.ps1
# macOS/Linux:
source venv/bin/activate

# Ch·∫°y server
python run_server.py
```

**Backend s·∫Ω ch·∫°y t·∫°i:**
- API: http://127.0.0.1:8000
- WebSocket: ws://127.0.0.1:8000/v1/ws
- API Docs: http://127.0.0.1:8000/docs

### Ch·∫°y Frontend (Terminal 2)

```bash
cd frontend

# Ch·∫°y dev server
npm run dev
```

**Frontend s·∫Ω ch·∫°y t·∫°i:** http://localhost:5173

### M·ªü tr√¨nh duy·ªát

Truy c·∫≠p: **http://localhost:5173**

## ‚öôÔ∏è C·∫•u h√¨nh

### Backend Configuration

Ch·ªânh s·ª≠a `backend/.env` (ho·∫∑c d√πng default):

```bash
# Server
HOST=127.0.0.1
PORT=8000
DEBUG=true

# Model paths (relative to backend/)
ASR_MODEL_PATH=../PhoWhisper-small
CLASSIFIER_MODEL_PATH=../phobert-vi-comment-4class

# Device: cpu, cuda, mps (Apple Silicon)
MODEL_DEVICE=cpu

# Audio settings
AUDIO_CHUNK_DURATION=2.0
MIN_AUDIO_DURATION=0.1
MAX_AUDIO_DURATION=30.0
TARGET_SAMPLE_RATE=16000

# CORS (Frontend URLs)
BACKEND_CORS_ORIGINS=http://localhost:5173,http://127.0.0.1:5173
```

### Frontend Configuration

Ch·ªânh s·ª≠a `frontend/configs/default.json`:

```json
{
  "api": {
    "baseURL": "http://127.0.0.1:8000",
    "wsURL": "ws://127.0.0.1:8000/v1/ws"
  },
  "audio": {
    "chunkDuration": 2000,
    "maxDuration": 30000
  }
}
```

## üîß Troubleshooting

### 1. FFmpeg kh√¥ng t√¨m th·∫•y

**L·ªói:**
```
FFmpeg not found or not working!
```

**Gi·∫£i ph√°p:**
- C√†i ƒë·∫∑t FFmpeg (xem B∆∞·ªõc 2)
- Ki·ªÉm tra FFmpeg trong PATH: `ffmpeg -version`
- Windows: Restart terminal sau khi c√†i FFmpeg

### 2. Models kh√¥ng load ƒë∆∞·ª£c

**L·ªói:**
```
OSError: Model path not found: ../PhoWhisper-small
```

**Gi·∫£i ph√°p:**
```bash
# Ch·∫°y l·∫°i download script
python download_models.py

# Ki·ªÉm tra models ƒë√£ t·ªìn t·∫°i
ls PhoWhisper-small/
ls phobert-vi-comment-4class/
```

### 3. Import error: ModuleNotFoundError

**L·ªói:**
```
ModuleNotFoundError: No module named 'transformers'
```

**Gi·∫£i ph√°p:**
```bash
# ƒê·∫£m b·∫£o venv ƒë√£ ƒë∆∞·ª£c k√≠ch ho·∫°t
cd backend
source venv/bin/activate  # macOS/Linux
.\venv\Scripts\Activate.ps1  # Windows

# C√†i l·∫°i dependencies
pip install -r requirements.txt
```

### 4. WebSocket connection failed

**L·ªói:**
```
WebSocket connection to 'ws://127.0.0.1:8000/v1/ws' failed
```

**Gi·∫£i ph√°p:**
- Ki·ªÉm tra backend ƒëang ch·∫°y: http://127.0.0.1:8000/docs
- Ki·ªÉm tra CORS trong `backend/.env`
- T·∫Øt VPN/Proxy n·∫øu c√≥
- Th·ª≠ ƒë·ªïi port trong config

### 5. Out of memory (OOM)

**L·ªói:**
```
RuntimeError: CUDA out of memory
```

**Gi·∫£i ph√°p:**
```bash
# Chuy·ªÉn sang CPU mode
# Trong backend/.env:
MODEL_DEVICE=cpu

# Gi·∫£m batch size (n·∫øu d√πng GPU)
ASR_BATCH_SIZE=2
CLASSIFIER_BATCH_SIZE=4
```

### 6. Audio kh√¥ng ƒë∆∞·ª£c nh·∫≠n di·ªán

**Ki·ªÉm tra:**
- Microphone permissions trong browser
- Audio format: WebM Opus codec (modern browsers)
- Th·ª≠ record audio ng·∫Øn (2-3 gi√¢y) tr∆∞·ªõc

### 7. Frontend build error

**L·ªói:**
```
Cannot find module '@/components/...'
```

**Gi·∫£i ph√°p:**
```bash
cd frontend
rm -rf node_modules package-lock.json
npm install
```

## üìö API Documentation

### REST API

Xem ƒë·∫ßy ƒë·ªß t·∫°i: **http://127.0.0.1:8000/docs** (khi backend ƒëang ch·∫°y)

#### Health Check
```http
GET /health
```

Response:
```json
{
  "status": "healthy",
  "version": "2.0.0",
  "timestamp": "2025-10-06T10:30:00Z"
}
```

### WebSocket API

**Endpoint:** `ws://127.0.0.1:8000/v1/ws`

#### Message Format

**Client ‚Üí Server (Audio chunk):**
```json
{
  "type": "audio",
  "data": "<base64_audio_data>",
  "format": "webm",
  "sampleRate": 48000
}
```

**Server ‚Üí Client (Transcript result):**
```json
{
  "type": "transcript",
  "text": "Xin ch√†o c√°c b·∫°n",
  "sentiment": {
    "label": "positive",
    "confidence": 0.95,
    "warning": false
  },
  "processingTime": 0.234
}
```

**Server ‚Üí Client (Error):**
```json
{
  "type": "error",
  "message": "Audio processing failed",
  "code": "AUDIO_DECODE_ERROR"
}
```

## üóÇÔ∏è C·∫•u tr√∫c Project

```
demo-stt-hds/
‚îú‚îÄ‚îÄ backend/                      # FastAPI Backend
‚îÇ   ‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ api/v1/              # API endpoints
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ core/                # Config, logger, metrics
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ models/              # AI model wrappers
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ phowhisper_asr.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ classifier.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ schemas/             # Pydantic schemas
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ services/            # Business logic
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ main.py              # FastAPI app
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt
‚îÇ   ‚îú‚îÄ‚îÄ run_server.py
‚îÇ   ‚îî‚îÄ‚îÄ .env.example
‚îú‚îÄ‚îÄ frontend/                    # React Frontend
‚îÇ   ‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ components/         # UI components
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ hooks/              # Custom React hooks
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ schemas/            # Zod validation schemas
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ stores/             # Zustand stores
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ types/              # TypeScript types
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ utils/              # Utilities
‚îÇ   ‚îú‚îÄ‚îÄ package.json
‚îÇ   ‚îî‚îÄ‚îÄ vite.config.ts
‚îú‚îÄ‚îÄ PhoWhisper-small/           # AI Model (ASR)
‚îú‚îÄ‚îÄ phobert-vi-comment-4class/  # AI Model (Classifier)
‚îú‚îÄ‚îÄ download_models.py          # Model download script
‚îî‚îÄ‚îÄ README.md
```

## üìö Additional Documentation

- üìñ [QUICKSTART.md](QUICKSTART.md) - Quick setup guide (< 5 min read)
- üèóÔ∏è [PROJECT_STRUCTURE.md](PROJECT_STRUCTURE.md) - Detailed architecture overview
- ü§ù [CONTRIBUTING.md](CONTRIBUTING.md) - How to contribute
- üìã [CHANGELOG.md](CHANGELOG.md) - Version history

## ü§ù Contributing

Contributions are welcome! Please read [CONTRIBUTING.md](CONTRIBUTING.md) for:
- Development workflow
- Coding standards
- Testing guidelines
- PR process

Quick start:
1. Fork the repository
2. Create a feature branch: `git checkout -b feature/your-feature`
3. Make your changes
4. Run tests: `pytest` (backend) / `npm test` (frontend)
5. Submit a Pull Request

## üìÑ License

[MIT License](LICENSE) - xem file LICENSE ƒë·ªÉ bi·∫øt th√™m chi ti·∫øt.

This project uses AI models from VinAI Research (PhoWhisper, PhoBERT) which are licensed separately. See LICENSE file for details.

## üë®‚Äçüíª Author

**HuynhSang2005**
- GitHub: [@HuynhSang2005](https://github.com/HuynhSang2005)

## üôè Acknowledgments

- [PhoWhisper](https://huggingface.co/vinai/PhoWhisper-small) - VinAI Research
- [PhoBERT](https://github.com/VinAIResearch/PhoBERT) - VinAI Research
- [FastAPI](https://fastapi.tiangolo.com/)
- [React](https://react.dev/)
- [Shadcn UI](https://ui.shadcn.com/)

---

**üéâ Happy Coding!** N·∫øu g·∫∑p v·∫•n ƒë·ªÅ, vui l√≤ng t·∫°o issue tr√™n GitHub.
